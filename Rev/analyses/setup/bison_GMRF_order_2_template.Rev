seed(THISSEED)  #442, 443, 444, 445

# The BEAST script has a total move weight of 75, distributed as
# 30 = 40%   pure node height
# 15 = 20%   mostly node-height but also tree moves (subtree slide)
# 21 = 28%   tree moves
# 3  = 4.0%  root height
# 1 ~= 1.3%  kappa
# 1 ~= 1.3%  base frequencies
# 1 ~= 1.3%  gamma shape parameter
# 3  = 4.0%  coalescent parameters

# Here we will allocate
# 40%   pure node height
# 20%   mostly node-height but also tree moves (subtree slide)
# 28%   tree moves
# 4.0%  root height
# 1.0%  kappa
# 1.0%  base frequencies
# 1.0%  gamma shape parameter
# 5.0%  coalescent parameters (3.0% delta thetas, 1.0% hyperpriors, 1.0% first population size

###------------------------------
##          Data 
###------------------------------

### Read in the sequence alignment
data <- readDiscreteCharacterData("data/bison_2013.nexus")

num_taxa <- data.ntaxa()
# Define the boundary X of last grid cell as so Pr(tmrca < X) = 0.001. 
# the population size from the last change point to infinity will be the same
grid_bound = 100000

### Read in taxa
taxa = readTaxonData("data/bison_2013_taxa.txt"," ")
num_taxa = taxa.size()

###-------------------------------
##          Set Grid    
###-------------------------------

# set my move index
mi = 0

# set move index for up-down moves
miud = 0

# define number of population sizes through time
NUM_INTERVALS = 120
NIM1 = NUM_INTERVALS - 1

# Chop up duration from root to present into equally sized intervals
interval_times <- grid_bound * seq(1, NIM1, 1)/NIM1

######################################
# Define population sizes and priors #
######################################


zeta <- 0.00085    #from fixed tree 120 cells and p=0.05 order2
zgam ~ dnHalfCauchy(0, 1)

zgam.setValue(runif(1, 0.05, 0.5)[1])

# Prior on population size at the present 
zlog_Ne1 ~ dnNormal(0, 1)

zlog_Ne1.setValue(rnorm(1,0,.1)[1])

moves[++mi] = mvSlideBactrian(zlog_Ne1,weight=1.7/100.0,sigma=1.0,tune=true) # RevBayes targets an acceptance of ~44% when autotuning by default, we can change this as we desire, as in this parameter where sampling has a lot of trouble


# Start accumulating vector of population sizes

logNe1 := 10.7 + 5*zlog_Ne1

s1_2 <- sqrt(1/2)

delta_logNe[1] ~ dnNormal( mean=0, sd=s1_2*zgam*zeta )


# model for changes in log population size
for (i in 1:(NUM_INTERVALS-2)) {

    # specify normal priors on order-2 differences in log pop size
    delta_logNe[i+1] ~ dnNormal( mean=0, sd=zeta*zgam)
    
}


Ne := fnassembleContinuousMRF(initialValue=logNe1,increments=delta_logNe,initialValueIsLogScale=true,order=2)

moves[++mi] = mvEllipticalSliceSamplingSimple(delta_logNe,weight=1.7/100.0,tune=false)
moves[++mi] = mvGMRFHyperpriorGibbs(zgam, delta_logNe, zeta, order=2, weight=1.6/100.0)




############################
# Coalescent prior on tree #
############################

print("got to tree model", "\n")

# Define our model
psi ~ dnHeterochronousCoalescentSkyline(theta  = Ne, times   = interval_times,  method  = "specified", taxa   = taxa)

## Tree proposals
# Moves on node times (excluding root height)
moves[++mi] = mvNodeTimeSlideUniform(psi, weight=20.0/100.0)
moves[++mi] = mvNodeTimeScale(psi, weight=20.0/100.0)
moves[++mi] = mvSubtreeScale(psi, weight=20.0/100.0)

# Moves on root height
moves[++mi] = mvRootTimeScaleBactrian(psi, weight=4.0/100.0)

# Moves on tree topology
total_tree_weight_BEAST = 28
moves[++mi] = mvNarrow(psi, weight=9.0/(9.0+9.0+168.0)*total_tree_weight_BEAST/100.0)
moves[++mi] = mvNNI(psi, weight=9.0/(9.0+9.0+168.0)*total_tree_weight_BEAST/100.0)
moves[++mi] = mvFNPR(psi, weight=168.0/(9.0+9.0+168.0)*total_tree_weight_BEAST/100.0)

TL := psi.treeLength()
RA := psi.rootAge()

######################
# Substitution model #
######################

print("got to sub model", "\n")

# Prior on kappa
kappa ~ dnGamma(shape=10,rate=1/3)
moves[++mi] = mvScaleBactrian(kappa, weight=1.0/100.0, lambda=1.0, tune=true, tuneTarget=0.44)

# Prior on stationary frequencies
pi ~ dnDirichlet(v(1,1,1,1))
moves[++mi] = mvBetaSimplex(pi, weight=0.75/100.0, alpha=1, tune=true)
moves[++mi] = mvDirichletSimplex(pi, alpha=1, weight=0.25/100.0, tune=true) 

# Wrap up kappa and pi into HKY model
Q := fnHKY(kappa, pi)


clock_rate <- 5.38e-7

# Gamma-distributed rate heterogeneity
# Prior on shape
gamma_shape ~ dnGamma(shape=3.25,rate=1/0.06)
moves[++mi] = mvScaleBactrian(gamma_shape, weight=1.0/100.0, lambda=1.0, tune=true, tuneTarget=0.44)

gamma_cats := fnDiscretizeGamma(gamma_shape, gamma_shape, 4)

#############
# The Model #
#############

seq ~ dnPhyloCTMC(tree=psi, Q=Q, branchRates=clock_rate, siteRates = gamma_cats, nSites=data.nchar())

seq.clamp(data)

### workspace model wrapper ###
mymodel = model(Ne)

### set up the monitors that will output parameter values to file and screen 
mni = 0
monitors[++mni] = mnModel(filename="output/bison_gmrf_2_chain_THISREP.log",printgen=64000, separator = TAB)
monitors[++mni] = mnFile(filename="output/bison_gmrf_2_chain_THISREP.trees",printgen=64000, separator = TAB, psi)
monitors[++mni] = mnScreen(printgen=64000, zlog_Ne1, zgam, gamma_shape)


################
# The Analysis #
################

### workspace mcmc ###
mymcmc = mcmc(mymodel, monitors, moves)

### pre-burnin to tune the proposals ###
mymcmc.burnin(generations=1000000,tuningInterval=1e4) #1 million, or 10% of the length of the chain we want
mymcmc.operatorSummary()

### run the MCMC ###
mymcmc.run(generations=80000000)  #80 million
mymcmc.operatorSummary()



## quit ##
#q()
